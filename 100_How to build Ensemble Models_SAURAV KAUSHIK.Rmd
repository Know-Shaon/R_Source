---
title: "How to build Ensemble Models"
author: "kishore"
date: "3/22/2017"
output: html_document
---

The objective of this book is to practice building ensemble models.
To use a package authored by Saurav Kaushik

Reference:
https://www.analyticsvidhya.com/blog/2017/02/introduction-to-ensembling-along-with-implementation-in-r/
https://www.analyticsvidhya.com/blog/2017/03/create-packages-r-cran-github/





```{r}
#Loading the required libraries
library('caret')
#Seeting the random seed
set.seed(1)

```




```{r}
#Loading the hackathon dataset
data<-read.csv(url('https://datahack-prod.s3.ap-south-1.amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))

```


```{r}
#Imputing missing values using median
preProcValues <- preProcess(data, method = c("medianImpute","center","scale"))
library('RANN')
data_processed <- predict(preProcValues, data)
sum(is.na(data_processed))
```



```{r}
#Spliting training set into two parts based on outcome: 75% and 25%
index <- createDataPartition(data_processed$Loan_Status, p=0.75, list=FALSE)
trainSet <- data_processed[ index,]
testSet <- data_processed[-index,]
```




```{r}
#Defining the training controls for multiple models
fitControl <- trainControl(
  method = "cv",
  number = 5,
savePredictions = 'final',
classProbs = T)

#Defining the predictors and outcome
predictors<-c("Credit_History", "LoanAmount", "Loan_Amount_Term", "ApplicantIncome","CoapplicantIncome")
outcomeName<-'Loan_Status'

```


Now let’s get started with training a random forest and test its accuracy on the test set that we have created:
```{r}

#Training the random forest model
model_rf<-train(trainSet[,predictors],trainSet[,outcomeName],method='rf',trControl=fitControl,tuneLength=3)

#Predicting using random forest model
testSet$pred_rf<-predict(object = model_rf,testSet[,predictors])

#Checking the accuracy of the random forest model
confusionMatrix(testSet$Loan_Status,testSet$pred_rf)
```
Confusion Matrix and Statistics

          Reference
Prediction  N  Y
         N 29 19
         Y  9 96
                                          
               Accuracy : 0.817           
                 95% CI : (0.7465, 0.8748)
    No Information Rate : 0.7516          
    P-Value [Acc > NIR] : 0.03458         
                                          
                  Kappa : 0.5495          
 Mcnemar's Test P-Value : 0.08897         
                                          
            Sensitivity : 0.7632          
            Specificity : 0.8348          
         Pos Pred Value : 0.6042          
         Neg Pred Value : 0.9143          
             Prevalence : 0.2484          
         Detection Rate : 0.1895          
   Detection Prevalence : 0.3137          
      Balanced Accuracy : 0.7990          
                                          
       'Positive' Class : N       








Well, as you can see, we got 0.81 accuracy with the individual random forest model. Let’s see the performance of KNN:
```{r}
#Training the knn model
model_knn<-train(trainSet[,predictors],trainSet[,outcomeName],method='knn',trControl=fitControl,tuneLength=3)
#Predicting using knn model
testSet$pred_knn<-predict(object = model_knn,testSet[,predictors])
#Checking the accuracy of the random forest model
confusionMatrix(testSet$Loan_Status,testSet$pred_knn)
```
Confusion Matrix and Statistics

          Reference
Prediction   N   Y
         N  29  19
         Y   2 103
                                         
               Accuracy : 0.8627         
                 95% CI : (0.7979, 0.913)
    No Information Rate : 0.7974         
    P-Value [Acc > NIR] : 0.0241694      
                                         
                  Kappa : 0.6473         
 Mcnemar's Test P-Value : 0.0004803      
                                         
            Sensitivity : 0.9355         
            Specificity : 0.8443         
         Pos Pred Value : 0.6042         
         Neg Pred Value : 0.9810         
             Prevalence : 0.2026         
         Detection Rate : 0.1895         
   Detection Prevalence : 0.3137         
      Balanced Accuracy : 0.8899         
                                         
       'Positive' Class : N         



It’s great since we are able to get 0.86 accuracy with the individual KNN model. Let’s see the performance of Logistic regression as well before we go on to create ensemble of these three.
```{r}
#Training the Logistic regression model
model_lr<-train(trainSet[,predictors],trainSet[,outcomeName],method='glm',trControl=fitControl,tuneLength=3)
#Predicting using knn model
testSet$pred_lr<-predict(object = model_lr,testSet[,predictors])

#Checking the accuracy of the random forest model
confusionMatrix(testSet$Loan_Status,testSet$pred_lr)

```
Confusion Matrix and Statistics

          Reference
Prediction   N   Y
         N  28  20
         Y   2 103
                                          
               Accuracy : 0.8562          
                 95% CI : (0.7904, 0.9076)
    No Information Rate : 0.8039          
    P-Value [Acc > NIR] : 0.0594340       
                                          
                  Kappa : 0.6282          
 Mcnemar's Test P-Value : 0.0002896       
                                          
            Sensitivity : 0.9333          
            Specificity : 0.8374          
         Pos Pred Value : 0.5833          
         Neg Pred Value : 0.9810          
             Prevalence : 0.1961          
         Detection Rate : 0.1830          
   Detection Prevalence : 0.3137          
      Balanced Accuracy : 0.8854          
                                          
       'Positive' Class : N     

And the logistic regression also gives us the accuracy of 0.86.





------Ensembling follows-------------------




Averaging: In this, we’ll average the predictions from the three models. Since the predictions are either ‘Y’ or ‘N’, averaging doesn’t make much sense for this binary classification. However, we can do averaging on the probabilities of observations to be in wither of these binary classes.

```{r}
#Predicting the probabilities
testSet$pred_rf_prob<-predict(object = model_rf,testSet[,predictors],type='prob')
testSet$pred_knn_prob<-predict(object = model_knn,testSet[,predictors],type='prob')
testSet$pred_lr_prob<-predict(object = model_lr,testSet[,predictors],type='prob')

#Taking average of predictions
testSet$pred_avg<-(testSet$pred_rf_prob$Y+testSet$pred_knn_prob$Y+testSet$pred_lr_prob$Y)/3

#Splitting into binary classes at 0.5
testSet$pred_avg<-as.factor(ifelse(testSet$pred_avg>0.5,'Y','N'))
```







Majority Voting: In majority voting, we’ll assign the prediction for the observation as predicted by the majority of models. Since we have three models for a binary classification task, a tie is not possible.
```{r}
#The majority vote
testSet$pred_majority<-as.factor(ifelse(testSet$pred_rf=='Y' & testSet$pred_knn=='Y','Y',ifelse(testSet$pred_rf=='Y' & testSet$pred_lr=='Y','Y',ifelse(testSet$pred_knn=='Y' & testSet$pred_lr=='Y','Y','N'))))

```







Weighted Average: Instead of taking simple average, we can take weighted average. Generally, the weights of predictions are high for more accurate models. Let’s assign 0.5 to logistic regression and 0.25 to KNN and random forest each.
```{r}
#Taking weighted average of predictions
testSet$pred_weighted_avg<-(testSet$pred_rf_prob$Y*0.25)+(testSet$pred_knn_prob$Y*0.25)+(testSet$pred_lr_prob$Y*0.5)

#Splitting into binary classes at 0.5
testSet$pred_weighted_avg<-as.factor(ifelse(testSet$pred_weighted_avg>0.5,'Y','N'))

```







#THE BELOW ARE THE STEPS TO BUILD A ENSIMBLING MODEL

1. Train the individual base layer models on training data.
2. Predict using each base layer model for training data and test data.
3. Now train the top layer model again on the predictions of the bottom layer models that has been made on the training data.
4. Finally, predict using the top layer model with the predictions of bottom layer models that has been made for testing data.



Step 1: Train the individual base layer models on training data
```{r}
#Defining the training control
fitControl <- trainControl(
method = "cv",
number = 10,
savePredictions = 'final', # To save out of fold predictions for best parameter combinantions
classProbs = T # To save the class probabilities of the out of fold predictions
)

#Defining the predictors and outcome
predictors<-c("Credit_History", "LoanAmount", "Loan_Amount_Term", "ApplicantIncome",
"CoapplicantIncome")
outcomeName<-'Loan_Status'



#Training the random forest model
model_rf<-train(trainSet[,predictors],trainSet[,outcomeName],method='rf',trControl=fitControl,tuneLength=3)

#Training the knn model
model_knn<-train(trainSet[,predictors],trainSet[,outcomeName],method='knn',trControl=fitControl,tuneLength=3)

#Training the logistic regression model
model_lr<-train(trainSet[,predictors],trainSet[,outcomeName],method='glm',trControl=fitControl,tuneLength=3)
```




Step 2: Predict using each base layer model for training data and test data
```{r}
#Predicting the out of fold prediction probabilities for training data
trainSet$OOF_pred_rf<-model_rf$pred$Y[order(model_rf$pred$rowIndex)]
trainSet$OOF_pred_knn<-model_knn$pred$Y[order(model_knn$pred$rowIndex)]
trainSet$OOF_pred_lr<-model_lr$pred$Y[order(model_lr$pred$rowIndex)]

#Predicting probabilities for the test data
testSet$OOF_pred_rf<-predict(model_rf,testSet[predictors],type='prob')$Y
testSet$OOF_pred_knn<-predict(model_knn,testSet[predictors],type='prob')$Y
testSet$OOF_pred_lr<-predict(model_lr,testSet[predictors],type='prob')$Y

```





Step 3: Now train the top layer model again on the predictions of the bottom layer models that has been made on the training data
First, let’s start with the GBM model as the top layer model.
```{r}
#Predictors for top layer models 
predictors_top<-c('OOF_pred_rf','OOF_pred_knn','OOF_pred_lr') 

#GBM as top layer model 
model_gbm<- train(trainSet[,predictors_top],trainSet[,outcomeName],method='gbm',trControl=fitControl,tuneLength=3)



#Logistic regression as top layer model
model_glm<-train(trainSet[,predictors_top],trainSet[,outcomeName],method='glm',trControl=fitControl,tuneLength=3)

```




Step 4: Finally, predict using the top layer model with the predictions of bottom layer models that has been made for testing data
```{r}
#predict using GBM top layer model
testSet$gbm_stacked<-predict(model_gbm,testSet[,predictors_top])
confusionMatrix(testSet$Loan_Status,testSet$gbm_stacked)
Accuracy : 0.8562 


#predict using logictic regression top layer model
testSet$glm_stacked<-predict(model_glm,testSet[,predictors_top])

confusionMatrix(testSet$Loan_Status,testSet$glm_stacked)
Accuracy : 0.8562 

```



# The following tis the implementation of package ensembleR
#load train and test data
```{r}
#https://datahack-prod.s3.ap-south-1.amazonaws.com/test_file/test_Y3wMUE5_7gLdaTN.csv
#https://datahack-prod.s3.ap-south-1.amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv

```

#Preprocess train data.
```{r}
train$Gender <- ifelse(train$Gender=='Female',0,1)
train$Married <- ifelse(train$Married=='Yes',0,1)
train$Dependents<- as.numeric(train$Dependents)
train$Education <- ifelse(train$Education=='Graduate',1,0)
train$Self_Employed<-ifelse(train$Self_Employed=='No',0,1)
train$Property_Area<-as.character(train$Property_Area)
train$Property_Area[train$Property_Area=='Rural']<-1
train$Property_Area[train$Property_Area=='Semiurban']<-2
train$Property_Area[train$Property_Area=='Urban']<-3
train$Property_Area=as.numeric(train$Property_Area)
library('caret')
preProcValues <- preProcess(train, method = c("knnImpute","center","scale"))
train_processed <- predict(preProcValues, train)
train_processed$Loan_Status<-ifelse(train_processed$Loan_Status=='N',0,1)
train_processed$Loan_Status<-as.factor(train_processed$Loan_Status)

```

#Preprocess the test data.
```{r}
test$Gender <- ifelse(test$Gender=='Female',0,1)
test$Married <- ifelse(test$Married=='Yes',0,1)
test$Dependents<- as.numeric(test$Dependents)
test$Education <- ifelse(test$Education=='Graduate',1,0)
test$Self_Employed<-ifelse(test$Self_Employed=='No',0,1)
test$Property_Area<-as.character(test$Property_Area)
test$Property_Area[test$Property_Area=='Rural']<-1
test$Property_Area[test$Property_Area=='Semiurban']<-2
test$Property_Area[test$Property_Area=='Urban']<-3
test$Property_Area=as.numeric(test$Property_Area)


preProcValues <- preProcess(test, method = c("knnImpute","center","scale"))
test_processed <- predict(preProcValues, test)

```


```{r}
install.packages('ensembleR')
library(ensembleR)

preds <- ensemble(train_processed[,c(predictors,'Loan_Status')],test_processed[,c(predictors,'Loan_Status')],'Loan_Status',c('rpart','treebag','knn','rf','svmLinear'),'gbm')
table(preds)


```



```{r}
test_processed$Loan_Status=preds
test_result =as.data.frame(test_processed[,c('Loan_ID','Loan_Status')])

Loan_file=test_result
Loan_file$Loan_Status=as.character(Loan_file$Loan_Status)
Loan_file$Loan_Status=as.numeric(Loan_file$Loan_Status)
Loan_file$Loan_Status[Loan_file$Loan_Status==1] <- "Y"
Loan_file$Loan_Status[Loan_file$Loan_Status==0] <- "N"

write.csv(Loan_file,file='Result_rf.csv',row.names=FALSE)

```


